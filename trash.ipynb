{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-api in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: databricks-cli in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-api) (0.18.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (8.1.7)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (2.9.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.17.3 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (2.32.3)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from click>=7.0->databricks-cli->databricks-api) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.17.3->databricks-cli->databricks-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.17.3->databricks-cli->databricks-api) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.17.3->databricks-cli->databricks-api) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install databricks-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'object_id': 4056003884218143}\n"
     ]
    }
   ],
   "source": [
    "# code to upload a multi celld notebook thingy\n",
    "from databricks_api import DatabricksAPI\n",
    "import base64\n",
    "import json\n",
    "\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=DATABRICKS_INSTANCE,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "notebook_content = {\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"print(\\\"Hello boch!\\\")\\n\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"print(\\\"hello korni.\\\")\\n\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\"\n",
    "        },\n",
    "        \"language_info\": {\n",
    "            \"codemirror_mode\": {\n",
    "                \"name\": \"ipython\",\n",
    "                \"version\": 3\n",
    "            },\n",
    "            \"file_extension\": \".py\",\n",
    "            \"mimetype\": \"text/x-python\",\n",
    "            \"name\": \"python\",\n",
    "            \"nbconvert_exporter\": \"python\",\n",
    "            \"pygments_lexer\": \"ipython3\",\n",
    "            \"version\": \"3.8.5\"\n",
    "        }\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 5\n",
    "}\n",
    "\n",
    "def create_notebook(path, content):\n",
    "\n",
    "    encoded_content = base64.b64encode(json.dumps(content).encode('utf-8')).decode('utf-8')\n",
    "\n",
    "    response = db.workspace.import_workspace(\n",
    "        path=path,\n",
    "        #change3d format from source to jupyter\n",
    "        format='JUPYTER',\n",
    "        language='PYTHON',\n",
    "        content=encoded_content\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "response = create_notebook(notebook_path, notebook_content)\n",
    "print(\"Response:\", response)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'job_id': 992109576305160}\n"
     ]
    }
   ],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "\n",
    "\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=DATABRICKS_INSTANCE,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "\n",
    "# bro create cluster then pass id \n",
    "\n",
    "job_config = {\n",
    "    \"name\": \"from code try\",  \n",
    "    \"existing_cluster_id\":\"0911-051026-t7k7800r\",  \n",
    "    \"notebook_task\": {\n",
    "        \"notebook_path\": notebook_path  # Path \n",
    "    }\n",
    "}\n",
    "\n",
    "def create_job(job_config):\n",
    "    response = db.jobs.create_job(**job_config)\n",
    "    return response\n",
    "\n",
    "\n",
    "response = create_job(job_config)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'job_id': 675250568259634}\n"
     ]
    }
   ],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "\n",
    "\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=DATABRICKS_INSTANCE,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# in case we got multi book things put the cluster specification withon the tasks\n",
    "job_config = {\n",
    "    \"name\": \"Job with Task Dependencies\",  \n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"task_key\": \"task1\",\n",
    "            \"notebook_task\": {\n",
    "                \"notebook_path\": notebook_path1\n",
    "            },\n",
    "            \"existing_cluster_id\": \"0911-051026-t7k7800r\"\n",
    "        },\n",
    "        {\n",
    "            \"task_key\": \"task2\",\n",
    "            \"depends_on\": [\n",
    "                {\"task_key\": \"task1\"}\n",
    "            ],\n",
    "            \"notebook_task\": {\n",
    "                \"notebook_path\": notebook_path2\n",
    "            },\n",
    "            \"existing_cluster_id\": \"0911-051026-t7k7800r\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def create_job(job_config):\n",
    "    response = db.jobs.create_job(**job_config)\n",
    "    return response\n",
    "\n",
    "\n",
    "response = create_job(job_config)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'trash.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add trash.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 0f17a27] job created no scheduling tho\n",
      " 1 file changed, 95 insertions(+), 107 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"job created no scheduling tho\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/gooberjuber/centific.1.1.git\n",
      "   ffdcfdd..0f17a27  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstaged changes after reset:\n",
      "M\ttrash.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git reset HEAD~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
