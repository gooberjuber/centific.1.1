{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-api in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: databricks-cli in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-api) (0.18.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (8.1.7)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (2.9.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.17.3 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (2.32.3)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.7 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from databricks-cli->databricks-api) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from click>=7.0->databricks-cli->databricks-api) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.17.3->databricks-cli->databricks-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.17.3->databricks-cli->databricks-api) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests>=2.17.3->databricks-cli->databricks-api) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install databricks-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'object_id': 4056003884218143}\n"
     ]
    }
   ],
   "source": [
    "# code to upload a multi celld notebook thingy\n",
    "from databricks_api import DatabricksAPI\n",
    "import base64\n",
    "import json\n",
    "\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=DATABRICKS_INSTANCE,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "notebook_content = {\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"print(\\\"Hello boch!\\\")\\n\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"print(\\\"hello korni.\\\")\\n\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\"\n",
    "        },\n",
    "        \"language_info\": {\n",
    "            \"codemirror_mode\": {\n",
    "                \"name\": \"ipython\",\n",
    "                \"version\": 3\n",
    "            },\n",
    "            \"file_extension\": \".py\",\n",
    "            \"mimetype\": \"text/x-python\",\n",
    "            \"name\": \"python\",\n",
    "            \"nbconvert_exporter\": \"python\",\n",
    "            \"pygments_lexer\": \"ipython3\",\n",
    "            \"version\": \"3.8.5\"\n",
    "        }\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 5\n",
    "}\n",
    "\n",
    "def create_notebook(path, content):\n",
    "\n",
    "    encoded_content = base64.b64encode(json.dumps(content).encode('utf-8')).decode('utf-8')\n",
    "\n",
    "    response = db.workspace.import_workspace(\n",
    "        path=path,\n",
    "        #change3d format from source to jupyter\n",
    "        format='JUPYTER',\n",
    "        language='PYTHON',\n",
    "        content=encoded_content\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "response = create_notebook(notebook_path, notebook_content)\n",
    "print(\"Response:\", response)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'job_id': 992109576305160}\n"
     ]
    }
   ],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "\n",
    "\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=DATABRICKS_INSTANCE,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "\n",
    "# bro create cluster then pass id \n",
    "\n",
    "job_config = {\n",
    "    \"name\": \"from code try\",  \n",
    "    \"existing_cluster_id\":\"0911-051026-t7k7800r\",  \n",
    "    \"notebook_task\": {\n",
    "        \"notebook_path\": notebook_path  # Path \n",
    "    }\n",
    "}\n",
    "\n",
    "def create_job(job_config):\n",
    "    response = db.jobs.create_job(**job_config)\n",
    "    return response\n",
    "\n",
    "\n",
    "response = create_job(job_config)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'job_id': 675250568259634}\n"
     ]
    }
   ],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "\n",
    "\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=DATABRICKS_INSTANCE,\n",
    "    token=DATABRICKS_TOKEN\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# in case we got multi book things put the cluster specification withon the tasks\n",
    "job_config = {\n",
    "    \"name\": \"Job with Task Dependencies\",  \n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"task_key\": \"task1\",\n",
    "            \"notebook_task\": {\n",
    "                \"notebook_path\": notebook_path1\n",
    "            },\n",
    "            \"existing_cluster_id\": \"0911-051026-t7k7800r\"\n",
    "        },\n",
    "        {\n",
    "            \"task_key\": \"task2\",\n",
    "            \"depends_on\": [\n",
    "                {\"task_key\": \"task1\"}\n",
    "            ],\n",
    "            \"notebook_task\": {\n",
    "                \"notebook_path\": notebook_path2\n",
    "            },\n",
    "            \"existing_cluster_id\": \"0911-051026-t7k7800r\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def create_job(job_config):\n",
    "    response = db.jobs.create_job(**job_config)\n",
    "    return response\n",
    "\n",
    "\n",
    "response = create_job(job_config)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
<<<<<<< HEAD
=======
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Run Response: {'run_id': 1003720147846431, 'number_in_job': 1003720147846431}\n"
     ]
    }
   ],
   "source": [
    "# simple job run \n",
    "\n",
    "job_id = '675250568259634'\n",
    "\n",
    "def run_job(job_id):\n",
    "    response = db.jobs.run_now(job_id=job_id)\n",
    "    return response\n",
    "\n",
    "run_response = run_job(job_id)\n",
    "print(\"Job Run Response:\", run_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'trash.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add trash.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
>>>>>>> 9a39337f7cfd019eb066d05cee0c9e134fffdaae
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Job Run Response: {'run_id': 1003720147846431, 'number_in_job': 1003720147846431}\n"
=======
      "[master d54382b] job created with multiple tasks and dependencies linked\n",
      " 1 file changed, 65 insertions(+), 31 deletions(-)\n"
>>>>>>> 9a39337f7cfd019eb066d05cee0c9e134fffdaae
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# simple job run \n",
    "\n",
    "job_id = '675250568259634'\n",
    "\n",
    "def run_job(job_id):\n",
    "    response = db.jobs.run_now(job_id=job_id)\n",
    "    return response\n",
    "\n",
    "run_response = run_job(job_id)\n",
    "print(\"Job Run Response:\", run_response)\n"
=======
    "!git commit -m \"job created with multiple tasks and dependencies linked\""
>>>>>>> 9a39337f7cfd019eb066d05cee0c9e134fffdaae
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Stat : {'job_id': 675250568259634, 'run_id': 1003720147846431, 'creator_user_name': 'gooberjuber@outlook.com', 'number_in_job': 1003720147846431, 'original_attempt_run_id': 1003720147846431, 'state': {'life_cycle_state': 'RUNNING', 'state_message': '', 'user_cancelled_or_timedout': False}, 'start_time': 1726052732414, 'setup_duration': 0, 'execution_duration': 0, 'cleanup_duration': 0, 'end_time': 0, 'run_duration': 468779, 'trigger': 'ONE_TIME', 'run_name': 'Job with Task Dependencies', 'run_page_url': 'https://adb-548767655017739.19.azuredatabricks.net/?o=548767655017739#job/675250568259634/run/1003720147846431', 'run_type': 'JOB_RUN', 'tasks': [{'run_id': 214911374985191, 'task_key': 'task1', 'run_if': 'ALL_SUCCESS', 'notebook_task': {'notebook_path': '/Workspace/Users/gooberjuber@outlook.com/code_multicella.ipynb', 'source': 'WORKSPACE'}, 'existing_cluster_id': '0911-051026-t7k7800r', 'state': {'life_cycle_state': 'PENDING', 'state_message': '', 'user_cancelled_or_timedout': False}, 'run_page_url': 'https://adb-548767655017739.19.azuredatabricks.net/?o=548767655017739#job/675250568259634/run/214911374985191', 'start_time': 1726052732438, 'setup_duration': 0, 'execution_duration': 0, 'cleanup_duration': 0, 'end_time': 0, 'cluster_instance': {'cluster_id': '0911-051026-t7k7800r'}, 'attempt_number': 0, 'status': {'state': 'PENDING'}}, {'run_id': 593510234722781, 'task_key': 'task2', 'depends_on': [{'task_key': 'task1'}], 'run_if': 'ALL_SUCCESS', 'notebook_task': {'notebook_path': '/Workspace/Users/gooberjuber@outlook.com/code_multicellz', 'source': 'WORKSPACE'}, 'existing_cluster_id': '0911-051026-t7k7800r', 'state': {'life_cycle_state': 'BLOCKED', 'state_message': '', 'user_cancelled_or_timedout': False}, 'run_page_url': 'https://adb-548767655017739.19.azuredatabricks.net/?o=548767655017739#job/675250568259634/run/593510234722781', 'start_time': 0, 'setup_duration': 0, 'execution_duration': 0, 'cleanup_duration': 0, 'end_time': 0, 'cluster_instance': {'cluster_id': '0911-051026-t7k7800r'}, 'attempt_number': 0, 'status': {'state': 'BLOCKED'}}], 'format': 'MULTI_TASK', 'status': {'state': 'RUNNING'}, 'job_run_id': 1003720147846431}\n",
      "dict_keys(['job_id', 'run_id', 'creator_user_name', 'number_in_job', 'original_attempt_run_id', 'state', 'start_time', 'setup_duration', 'execution_duration', 'cleanup_duration', 'end_time', 'run_duration', 'trigger', 'run_name', 'run_page_url', 'run_type', 'tasks', 'format', 'status', 'job_run_id'])\n",
      "{'life_cycle_state': 'RUNNING', 'state_message': '', 'user_cancelled_or_timedout': False}\n",
      "{'state': 'RUNNING'}\n"
     ]
    }
   ],
   "source": [
    "run_id = '1003720147846431'\n",
    "\n",
    "def get_run_status(run_id):\n",
    "    response = db.jobs.get_run(run_id=run_id)\n",
    "    return response\n",
    "\n",
    "run_status = get_run_status(run_id)\n",
    "print(\"Run Stat :\", run_status)\n",
    "\n",
    "print(run_status.keys())\n",
    "print(run_status['state'])\n",
    "print(run_status['status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Stat : {'job_id': 675250568259634, 'run_id': 1003720147846431, 'creator_user_name': 'gooberjuber@outlook.com', 'number_in_job': 1003720147846431, 'original_attempt_run_id': 1003720147846431, 'state': {'life_cycle_state': 'TERMINATED', 'result_state': 'CANCELED', 'state_message': 'Run cancelled.', 'user_cancelled_or_timedout': True}, 'start_time': 1726052732414, 'setup_duration': 0, 'execution_duration': 0, 'cleanup_duration': 0, 'end_time': 1726053223419, 'run_duration': 491005, 'trigger': 'ONE_TIME', 'run_name': 'Job with Task Dependencies', 'run_page_url': 'https://adb-548767655017739.19.azuredatabricks.net/?o=548767655017739#job/675250568259634/run/1003720147846431', 'run_type': 'JOB_RUN', 'tasks': [{'run_id': 214911374985191, 'task_key': 'task1', 'run_if': 'ALL_SUCCESS', 'notebook_task': {'notebook_path': '/Workspace/Users/gooberjuber@outlook.com/code_multicella.ipynb', 'source': 'WORKSPACE'}, 'existing_cluster_id': '0911-051026-t7k7800r', 'state': {'life_cycle_state': 'TERMINATED', 'result_state': 'CANCELED', 'state_message': 'Run cancelled.', 'user_cancelled_or_timedout': True}, 'run_page_url': 'https://adb-548767655017739.19.azuredatabricks.net/?o=548767655017739#job/675250568259634/run/214911374985191', 'start_time': 1726052732438, 'setup_duration': 0, 'execution_duration': 0, 'cleanup_duration': 490000, 'end_time': 1726053223178, 'cluster_instance': {'cluster_id': '0911-051026-t7k7800r'}, 'attempt_number': 0, 'status': {'state': 'TERMINATED', 'termination_details': {'code': 'CANCELED', 'type': 'CLIENT_ERROR', 'message': 'Run cancelled.'}}}, {'run_id': 593510234722781, 'task_key': 'task2', 'depends_on': [{'task_key': 'task1'}], 'run_if': 'ALL_SUCCESS', 'notebook_task': {'notebook_path': '/Workspace/Users/gooberjuber@outlook.com/code_multicellz', 'source': 'WORKSPACE'}, 'existing_cluster_id': '0911-051026-t7k7800r', 'state': {'life_cycle_state': 'SKIPPED', 'result_state': 'UPSTREAM_CANCELED', 'state_message': 'Skipped because upstream task was cancelled or timed out', 'user_cancelled_or_timedout': True}, 'run_page_url': 'https://adb-548767655017739.19.azuredatabricks.net/?o=548767655017739#job/675250568259634/run/593510234722781', 'start_time': 0, 'setup_duration': 0, 'execution_duration': 0, 'cleanup_duration': 0, 'end_time': 1726053215277, 'cluster_instance': {'cluster_id': '0911-051026-t7k7800r'}, 'attempt_number': 0, 'status': {'state': 'TERMINATED', 'termination_details': {'code': 'SKIPPED', 'type': 'SUCCESS', 'message': 'Skipped because upstream task was cancelled or timed out'}}}], 'format': 'MULTI_TASK', 'status': {'state': 'TERMINATED', 'termination_details': {'code': 'CANCELED', 'type': 'CLIENT_ERROR', 'message': 'Run cancelled.'}}, 'job_run_id': 1003720147846431}\n",
      "dict_keys(['job_id', 'run_id', 'creator_user_name', 'number_in_job', 'original_attempt_run_id', 'state', 'start_time', 'setup_duration', 'execution_duration', 'cleanup_duration', 'end_time', 'run_duration', 'trigger', 'run_name', 'run_page_url', 'run_type', 'tasks', 'format', 'status', 'job_run_id'])\n",
      "{'life_cycle_state': 'TERMINATED', 'result_state': 'CANCELED', 'state_message': 'Run cancelled.', 'user_cancelled_or_timedout': True}\n",
      "{'state': 'TERMINATED', 'termination_details': {'code': 'CANCELED', 'type': 'CLIENT_ERROR', 'message': 'Run cancelled.'}}\n"
     ]
    }
   ],
   "source": [
    "run_id = '1003720147846431'\n",
    "\n",
    "def get_run_status(run_id):\n",
    "    response = db.jobs.get_run(run_id=run_id)\n",
    "    return response\n",
    "\n",
    "run_status = get_run_status(run_id)\n",
    "print(\"Run Stat :\", run_status)\n",
    "\n",
    "print(run_status.keys())\n",
    "print(run_status['state'])\n",
    "print(run_status['status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add trash.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.idea/\n",
      "\t__pycache__/\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"task run status can be checked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
=======
   "execution_count": 28,
>>>>>>> 9a39337f7cfd019eb066d05cee0c9e134fffdaae
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/gooberjuber/centific.1.1.git\n",
<<<<<<< HEAD
      "   d54382b..9a39337  master -> master\n"
=======
      "   0f17a27..d54382b  master -> master\n"
>>>>>>> 9a39337f7cfd019eb066d05cee0c9e134fffdaae
     ]
    }
   ],
   "source": [
    "!git push"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git reset --soft HEAD~1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> 9a39337f7cfd019eb066d05cee0c9e134fffdaae
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
